import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn
from keras.datasets import cifar10


(X_train, y_train), (X_test, y_test) = cifar10.load_data()


#0. Airplanes
#1. Cars
#2. Birds
#3. Cats
#4. Deers
#5. Dogs
#6. Frogs
#7. Horses
#8. Ships
#9. Trucks





X_train.shape


#50,000 images, each image consists 32x32 and 3 channels


X_train.shape


X_test.shape


y_train.shape


y_test.shape


#Data Visualization


i = 2345
plt.imshow(X_train[i])
print(y_train[i]) #x represents the image, y represents the class


W_grid = 15


L_grid = 15


fig, axes = plt.subplots(L_grid, W_grid, figsize = (25, 25))
axes = axes.ravel()

n_training = len(X_train)

for x in np.arange(0, L_grid * W_grid): # Adding a random image in each cell in the 15x15 grid
    index = np.random.randint(0, n_training) # Picking a random number
    axes[x].imshow(X_train[index])
    axes[x].set_title(y_train[index])
    axes[x].axis('off')
plt.subplots_adjust(hspace = 0.4)


n_training


# Data preparation


X_train = X_train.astype('float32')
X_test = X_test.astype('float32')


number_cat = 10


import keras
y_train = keras.utils.to_categorical(y_train, number_cat)
y_test = keras.utils.to_categorical(y_test, number_cat)


X_train = X_train/255# Data normalization
X_test = X_test/255


X_train.shape


Input_shape = X_train.shape[1:]


Input_shape



# training the model
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, Dropout
from keras.optimizers import Adam
from keras.callbacks import TensorBoard 

#Keras flow as the API and tensorflow as the backend


cnn_model = Sequential()
cnn_model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = "relu", input_shape = Input_shape)) #feature detection, applying filter
cnn_model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = "relu")) #Adding convolutional layers
cnn_model.add(MaxPooling2D(2,2)) #maxpooling
cnn_model.add(Dropout(0.4)) #dropping out for efficiency


cnn_model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = "relu")) #feature detection, applying filter
cnn_model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = "relu"))
cnn_model.add(MaxPooling2D(2,2)) #maxpooling
cnn_model.add(Dropout(0.4)) 

cnn_model.add(Flatten())

cnn_model.add(Dense(units=512, activation='relu'))

cnn_model.add(Dense(units=512, activation='relu'))

cnn_model.add(Dense(units=10, activation='softmax'))


cnn_model.compile(
    loss='categorical_crossentropy',
    optimizer= keras.optimizers.legacy.RMSprop(learning_rate=0.001),
    metrics=['accuracy']
)
y_test.shape



history = cnn_model.fit(X_train, y_train, batch_size=16, epochs=2, shuffle=True)


# Evaluating the model
evaluation = cnn_model.evaluate(X_test, y_test)
print('Test Accuracy: {}'.format(evaluation[1])) # has to be new data (testing data), prevents overfitting




predicted_classes = cnn_model.predict(X_test) #tells what are the predicted classes
predicted_classes = np.argmax(predicted_classes, axis=1)



X_test = X_test


y_test = y_test.argmax(1)



L = 7
W = 7
fig, axes = plt.subplots(L, W, figsize = (12,12))
axes = axes.ravel()
for i in np.arange(0,  L*W):
  axes[i].imshow(X_test[i])
  axes[i].set_title('Prediction = {}\nTrue= {}'.format(predicted_classes[i], y_test[i]))
  axes[i].axis('off')

plt.subplots_adjust(wspace= 1)




from sklearn.metrics import confusion_matrix
import seaborn as sns


cm = confusion_matrix(y_test, predicted_classes)
cm
plt.figure(figsize = (10, 10))
sns.heatmap(cm, annot = True)


# Saving the model


import os
directory = os.path.join(os.getcwd(), 'saved_models')

if not os.path.isdir(directory):
    os.makedirs(directory)
model_path = os.path.join(directory, 'keras_cifar10_trained_model.h5')
cnn_model.save(model_path)
     


# data augmentation
